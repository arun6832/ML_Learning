{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Lab3: Created by Jibrael Jos,PhD\n",
    "### Topic: Neural Network Explorations\n",
    "### Student Name: Naveen Krishna\n",
    "### Roll No:23122023\n",
    "### Date: 15 March\n",
    "### Submission : 4th April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer dataset parameters.\n",
    "num_classes = 2 # total classes \n",
    "num_features = 10 # data features \n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.01\n",
    "training_steps = 5000\n",
    "display_step = 500\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 28 # 1st layer number of neurons.\n",
    "n_hidden_2 = 56 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius  texture  perimeter    area        s        c  concavity       cp  \\\n",
      "0     17.99    10.38     122.80  1001.0  0.11840  0.27760    0.30010  0.14710   \n",
      "1     20.57    17.77     132.90  1326.0  0.08474  0.07864    0.08690  0.07017   \n",
      "2     19.69    21.25     130.00  1203.0  0.10960  0.15990    0.19740  0.12790   \n",
      "3     11.42    20.38      77.58   386.1  0.14250  0.28390    0.24140  0.10520   \n",
      "4     20.29    14.34     135.10  1297.0  0.10030  0.13280    0.19800  0.10430   \n",
      "..      ...      ...        ...     ...      ...      ...        ...      ...   \n",
      "564   21.56    22.39     142.00  1479.0  0.11100  0.11590    0.24390  0.13890   \n",
      "565   20.13    28.25     131.20  1261.0  0.09780  0.10340    0.14400  0.09791   \n",
      "566   16.60    28.08     108.30   858.1  0.08455  0.10230    0.09251  0.05302   \n",
      "567   20.60    29.33     140.10  1265.0  0.11780  0.27700    0.35140  0.15200   \n",
      "568    7.76    24.54      47.92   181.0  0.05263  0.04362    0.00000  0.00000   \n",
      "\n",
      "        sym       fd  ...  texture2  perimeter2   area2       s2       c2  \\\n",
      "0    0.2419  0.07871  ...     17.33      184.60  2019.0  0.16220  0.66560   \n",
      "1    0.1812  0.05667  ...     23.41      158.80  1956.0  0.12380  0.18660   \n",
      "2    0.2069  0.05999  ...     25.53      152.50  1709.0  0.14440  0.42450   \n",
      "3    0.2597  0.09744  ...     26.50       98.87   567.7  0.20980  0.86630   \n",
      "4    0.1809  0.05883  ...     16.67      152.20  1575.0  0.13740  0.20500   \n",
      "..      ...      ...  ...       ...         ...     ...      ...      ...   \n",
      "564  0.1726  0.05623  ...     26.40      166.10  2027.0  0.14100  0.21130   \n",
      "565  0.1752  0.05533  ...     38.25      155.00  1731.0  0.11660  0.19220   \n",
      "566  0.1590  0.05648  ...     34.12      126.70  1124.0  0.11390  0.30940   \n",
      "567  0.2397  0.07016  ...     39.42      184.60  1821.0  0.16500  0.86810   \n",
      "568  0.1587  0.05884  ...     30.37       59.16   268.6  0.08996  0.06444   \n",
      "\n",
      "     concavity2     cp2    sym2      fd2  diagnosis  \n",
      "0        0.7119  0.2654  0.4601  0.11890          1  \n",
      "1        0.2416  0.1860  0.2750  0.08902          1  \n",
      "2        0.4504  0.2430  0.3613  0.08758          1  \n",
      "3        0.6869  0.2575  0.6638  0.17300          1  \n",
      "4        0.4000  0.1625  0.2364  0.07678          1  \n",
      "..          ...     ...     ...      ...        ...  \n",
      "564      0.4107  0.2216  0.2060  0.07115          1  \n",
      "565      0.3215  0.1628  0.2572  0.06637          1  \n",
      "566      0.3403  0.1418  0.2218  0.07820          1  \n",
      "567      0.9387  0.2650  0.4087  0.12400          1  \n",
      "568      0.0000  0.0000  0.2871  0.07039          0  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv(\"cancerAllv3.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 3.001e-01 1.471e-01 2.419e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 8.690e-02 7.017e-02 1.812e-01]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 1.974e-01 1.279e-01 2.069e-01]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 9.251e-02 5.302e-02 1.590e-01]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 3.514e-01 1.520e-01 2.397e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 0.000e+00 1.587e-01]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "features=['radius','texture','perimeter','area','s','c','concavity','cp','sym']\n",
    "          \n",
    "import numpy as np\n",
    "X = np.array(df)\n",
    "y = X[:,30]\n",
    "X = X[:,0:9]\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.25,  \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.61529582e-02 2.63015545e-02 1.67383178e-01 ... 8.46362372e-05\n",
      "  7.85437867e-05 4.15857509e-04]\n",
      " [2.94403288e-02 3.33261284e-02 1.86572349e-01 ... 3.33531131e-05\n",
      "  3.69420807e-05 3.91008583e-04]\n",
      " [3.18381269e-02 6.13886719e-02 2.02842712e-01 ... 1.57467114e-05\n",
      "  3.49718009e-05 5.61240998e-04]\n",
      " ...\n",
      " [2.96343386e-02 2.66434656e-02 1.88699395e-01 ... 6.94486213e-05\n",
      "  4.65917657e-05 3.78935386e-04]\n",
      " [2.77436915e-02 4.45105311e-02 1.76787627e-01 ... 6.36416157e-05\n",
      "  4.99145197e-05 4.42451567e-04]\n",
      " [2.50847504e-02 3.23667866e-02 1.59714095e-01 ... 7.17015595e-05\n",
      "  5.62149648e-05 3.12087270e-04]]\n",
      "[[1.39825003e-02 1.11100014e-02 9.07477796e-02 ... 7.52259805e-05\n",
      "  5.45195142e-05 1.10584768e-04]\n",
      " [2.28115566e-02 3.92305915e-02 1.51240125e-01 ... 2.57352680e-04\n",
      "  1.51570487e-04 3.71823417e-04]\n",
      " [2.12454202e-02 2.39496349e-02 1.43115363e-01 ... 3.39482955e-04\n",
      "  1.72237676e-04 3.32549071e-04]\n",
      " ...\n",
      " [2.54446993e-02 3.33275669e-02 1.64662129e-01 ... 7.74317124e-05\n",
      "  5.97700976e-05 4.23080490e-04]\n",
      " [2.54669830e-02 3.86668285e-02 1.66103125e-01 ... 2.08845482e-04\n",
      "  8.90330593e-05 3.10835072e-04]\n",
      " [2.78670784e-02 3.61159271e-02 1.78692802e-01 ... 1.04695065e-04\n",
      "  7.08530144e-05 4.55500943e-04]]\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_test = x_train / 255., x_test / 255.\n",
    "X_train=tf.keras.utils.normalize(X_train, axis=-1, order=2)\n",
    "X_test=tf.keras.utils.normalize(X_test, axis=-1, order=2)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create TF Model.\n",
    "class NeuralNet(Model):\n",
    "        # Set layers.\n",
    "        def __init__(self):\n",
    "            super(NeuralNet, self).__init__()\n",
    "            # First fully-connected hidden layer.\n",
    "            self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "            # First fully-connected hidden layer.\n",
    "            self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "            # Second fully-connecter hidden layer.\n",
    "            self.out = layers.Dense(num_classes)\n",
    "\n",
    "        # Set forward pass.\n",
    "        def call(self, x, is_training=False):\n",
    "            x = self.fc1(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.out(x)\n",
    "            if not is_training:\n",
    "                # tf cross entropy expect logits without softmax, so only\n",
    "                # apply softmax when not training.\n",
    "                x = tf.nn.softmax(x)\n",
    "            return x\n",
    "\n",
    "    # Build neural network model.\n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    \n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    \n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "# optimizer = tf.optimizers.SGD(learning_rate)\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "#optimizer = tf.optimizers.RMSprop(learning_rate)\n",
    "#optimizer = tf.optimizers.Adagrad(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = neural_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = neural_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.657261, accuracy: 0.633803\n",
      "loss: 0.249210, accuracy: 0.896714\n",
      "loss: 0.168855, accuracy: 0.929577\n",
      "loss: 0.147256, accuracy: 0.938967\n",
      "loss: 0.146559, accuracy: 0.931925\n",
      "loss: 0.135507, accuracy: 0.953052\n",
      "loss: 0.131888, accuracy: 0.946009\n",
      "loss: 0.129692, accuracy: 0.950704\n",
      "loss: 0.129194, accuracy: 0.950704\n",
      "loss: 0.132066, accuracy: 0.943662\n"
     ]
    }
   ],
   "source": [
    "for step in range(training_steps):\n",
    "        run_optimization(X_train, y_train)\n",
    "    \n",
    "    \n",
    "        if(step%display_step==0):\n",
    "            pred = neural_net(X_train, is_training=True)\n",
    "            loss = cross_entropy_loss(pred, y_train)\n",
    "            acc = accuracy(pred, y_train)\n",
    "            print(\"loss: %f, accuracy: %f\" % ( loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.937063\n"
     ]
    }
   ],
   "source": [
    "# Test model on validation set.\n",
    "pred = neural_net(X_test, is_training=False)\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
