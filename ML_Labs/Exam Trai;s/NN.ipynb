{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arunp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\losses.py:2664: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PCA 1     PCA 2     PCA 3     PCA 4\n",
      "0      0.264562  0.380113  0.722649 -1.578952\n",
      "1      0.822315  2.292514 -0.418262  0.167787\n",
      "2      0.156114 -0.825565 -0.478057  0.078284\n",
      "3     -0.288905 -0.143887  0.312930  0.587398\n",
      "4      1.654264 -0.365432 -0.869909 -0.452555\n",
      "...         ...       ...       ...       ...\n",
      "12839 -4.420308 -2.086314  0.563676 -0.010408\n",
      "12840  2.833356 -0.026164 -0.838516 -1.202145\n",
      "12841 -1.392419 -0.791279 -1.311929  0.051785\n",
      "12842 -0.332588 -0.334212 -1.833260 -0.007769\n",
      "12843 -0.108591 -0.351896 -0.088934  1.536899\n",
      "\n",
      "[12844 rows x 4 columns]\n",
      "x_train shape: (10275, 4)\n",
      "x_test shape: (2569, 4)\n",
      "y_train shape: (10275,)\n",
      "y_test shape: (2569,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is already defined and read from 'data.csv'\n",
    "df = pd.read_csv('all_seasons.csv')\n",
    "\n",
    "# Select multiple columns to stack\n",
    "columns_to_stack = ['gp', 'pts', 'reb', 'net_rating', 'ts_pct', 'net_rating', 'ast_pct', 'age']\n",
    "\n",
    "# Extract these columns as a 2D NumPy array\n",
    "data_to_stack = df[columns_to_stack].to_numpy()\n",
    "\n",
    "# Standardization using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_standardized = scaler.fit_transform(data_to_stack)\n",
    "\n",
    "# Apply PCA\n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(data_standardized)\n",
    "\n",
    "# Convert the PCA result to a DataFrame\n",
    "X = pd.DataFrame(X_pca, columns=[f'PCA {i+1}' for i in range(n_components)])\n",
    "print(X)\n",
    "\n",
    "# Extract the target variable\n",
    "y = df['usg_pct'].to_numpy()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Verify the shapes of the split data\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arunp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\__init__.py:300: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,433\n",
      "Trainable params: 2,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the neural network using TensorFlow/Keras\n",
    "def create_neural_network(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Create the neural network\n",
    "input_dim = x_train.shape[1]\n",
    "model = create_neural_network(input_dim)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\arunp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\tf_utils.py:490: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer_utils.py:380: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "257/257 [==============================] - 2s 3ms/step - loss: 0.0037 - mae: 0.0427 - val_loss: 0.0024 - val_mae: 0.0344\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0027 - val_mae: 0.0357\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.0022 - val_mae: 0.0318\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0335 - val_loss: 0.0024 - val_mae: 0.0331\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0323 - val_loss: 0.0023 - val_mae: 0.0325\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0022 - val_mae: 0.0323\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0036 - val_mae: 0.0351\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0021 - val_mae: 0.0316\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0024 - val_mae: 0.0351\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0319 - val_loss: 0.0022 - val_mae: 0.0321\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0022 - val_mae: 0.0329\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0023 - val_mae: 0.0324\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0022 - val_mae: 0.0320\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0022 - val_mae: 0.0322\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0310 - val_loss: 0.0022 - val_mae: 0.0320\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0025 - val_mae: 0.0324\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0021 - val_mae: 0.0324\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0020 - val_mae: 0.0317\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0022 - val_mae: 0.0315\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0020 - val_mae: 0.0311\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0021 - val_mae: 0.0316\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0020 - val_mae: 0.0311\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0019 - val_mae: 0.0307\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0020 - val_mae: 0.0307\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0019 - val_mae: 0.0307\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0021 - val_mae: 0.0314\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0317\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0020 - val_mae: 0.0314\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0019 - val_mae: 0.0311\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0022 - val_mae: 0.0314\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0314\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0020 - val_mae: 0.0311\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0019 - val_mae: 0.0307\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0022 - val_mae: 0.0322\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0311\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0019 - val_mae: 0.0304\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0019 - val_mae: 0.0304\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0019 - val_mae: 0.0304\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0305\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0020 - val_mae: 0.0305\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0021 - val_mae: 0.0317\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0019 - val_mae: 0.0307\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0021 - val_mae: 0.0312\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0307\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0307\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0019 - val_mae: 0.0307\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0019 - val_mae: 0.0309\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0021 - val_mae: 0.0313\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0020 - val_mae: 0.0305\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0021 - val_mae: 0.0312\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0305\n",
      "Test Loss: 0.0016, Test MAE: 0.0305\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, mae = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f'Test Loss: {loss:.4f}, Test MAE: {mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score for training data: 0.4457\n",
      "R² score for testing data: 0.4121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(f'R² score for training data: {r2_train:.4f}')\n",
    "print(f'R² score for testing data: {r2_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 991us/step\n",
      "81/81 [==============================] - 0s 934us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m y_test_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Calculate accuracy score\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_test_pred_classes)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy score for training data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Predict using the trained model\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Calculate accuracy score\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred_classes)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n",
    "\n",
    "print(f'Accuracy score for training data: {train_accuracy:.4f}')\n",
    "print(f'Accuracy score for testing data: {test_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
